#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsart
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Regression& Regularization Exercise
\end_layout

\begin_layout Author
Elia Yakin & Lital Bridavsky
\end_layout

\begin_layout Subsection*
Developing the Ridge coeficiant 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $L\left(\cdot\right)$
\end_inset

 be:
\begin_inset Formula 
\begin{align*}
L\left(y,\hat{y}\right) & =\sum_{i=1}^{N}\left(y^{\left(i\right)}-\hat{y}^{\left(i\right)}\right)^{2}+\lambda\left\Vert w\right\Vert _{2}^{2}
\end{align*}

\end_inset

 we need to show that 
\begin_inset Formula $w_{Ridge}=\left(X^{T}X+\lambda I\right)^{-1}X^{T}y$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L\left(y,\hat{y}\right) & =\sum_{i=1}^{N}\left(y^{\left(i\right)}-\hat{y}^{\left(i\right)}\right)^{2}+\lambda\left\Vert w\right\Vert _{2}^{2}\\
 & =\left(y-\hat{y}\right)^{T}\left(y-\hat{y}\right)+\lambda w^{T}w\\
 & =\left(y-X^{T}w\right)^{T}\left(y-X^{T}w\right)+\lambda w^{T}w\\
 & =y^{T}y-2w^{T}X^{T}y+w^{T}X^{T}Xw+\lambda w^{T}w
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
taking the derivative by 
\begin_inset Formula $w$
\end_inset


\begin_inset Formula 
\begin{align*}
\frac{\partial L}{\partial w} & =0-2X^{T}y+2X^{T}Xw+2\lambda w\underset{FOC}{=}0\\
\iff & \left(X^{T}X+\lambda I\right)w=X^{T}y\\
\implies & w_{Ridge}=\left(X^{T}X+\lambda I\right)^{-1}X^{T}y
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection*
Bonus question:
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $G\sim N\left(1,\sigma^{2}\right)$
\end_inset

 and 
\begin_inset Formula $X^{\prime}=X\cdot G$
\end_inset

 s.t 
\begin_inset Formula $EX^{\prime}=E\left[X\cdot G\right]=EX$
\end_inset

 
\end_layout

\begin_layout Standard
First notice the followig property about 
\begin_inset Formula $G$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Var\left(G\right) & =\sigma^{2}=E\left(G-EG\right)^{2}=EG^{2}-E^{2}G\underset{EG=1}{=}EG^{2}-1\iff EG^{2}=\sigma^{2}+1
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now looking back on the loss of OLS we can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L & =\left\Vert y-w^{T}X^{\prime}\right\Vert ^{2}\\
 & =\left(y-Gw^{T}X\right)^{T}\left(y-Gw^{T}X\right)\\
 & =\left[y^{T}y-2Gw^{T}X^{T}y+G^{2}w^{T}X^{T}Xw\right]\\
 & =\left[y^{T}y-G2w^{T}X^{T}y+G^{2}w^{T}X^{T}Xw\right]\\
\\
EL & =E\left[y^{T}y-G2w^{T}X^{T}y+G^{2}w^{T}X^{T}Xw\right]\\
 & =E\left[y^{T}y\right]-2EGEw^{T}X^{T}y+EG^{2}E\left[w^{T}X^{T}Xw\right]\\
 & =E\left[y^{T}y\right]-2Ew^{T}X^{T}y+\left(1+\sigma^{2}\right)E\left[w^{T}X^{T}Xw\right]\\
 & =MSE\left(L\right)+\sigma^{2}E\left[w^{T}X^{T}Xw\right]\\
 & =MSE\left(L\right)+\sigma^{2}w^{T}E\left[X^{T}X\right]w\\
 & =MSE\left(L\right)+\sigma^{2}\cdot\sigma_{X}^{2}w^{T}w\\
 & \underset{*}{=}MSE\left(L\right)+\sigma^{2}\cdot w^{T}w
\end{align*}

\end_inset

 * if 
\begin_inset Formula $X$
\end_inset

 is noramilized and 
\begin_inset Formula $\forall l,m\in\left\{ 1,2,\dots,p\right\} \ s.t\ l\neq m\ Cov\left(x_{l},x_{m}\right)=0$
\end_inset

 then 
\begin_inset Formula $\sigma_{X}^{2}=I_{p}$
\end_inset

 and 
\begin_inset Formula $X\sim N\left(0,I_{p}\right)$
\end_inset


\end_layout

\begin_layout Standard
From the above we can see that we get the Ridge Loss with 
\begin_inset Formula $\lambda=\sigma^{2}$
\end_inset

 
\end_layout

\end_body
\end_document
